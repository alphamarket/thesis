\زیرزیرقسمت{سیاست انتخاب عمل «بولتزمن»}

\fig[.8]{boltzmann/prey.pref.compare.png}{مقایسه در سرعت و کیفیت یادگیری در محیط صید و صیاد با تابع بولتزمن در محیط صید و صیاد}

\begin{table}
\centering
\caption{مقایسه در میزان درصد بهبود کیفیت یادگیری در محیط صید و صیاد با تابع بولتزمن}\label{tab:prey_pref_compare}
\begin{latin}
\begin{tabular}{|*8{l|}}
\hline
\multicolumn{3}{|c|}{}& \multicolumn{5}{c|}{REFMAT}
\\\hline
& IL & SEP & wsum & fci-mean & fci-max & fci-k-mean & fci-const-one
\\\hline
IL &0.0 & & & & & &
\\\hline
SEP &3.3 &0.0 & & & & &
\\\hline
wsum &3.1 &-0.2 &0.0 & & & &
\\\hline
fci-mean &16.7 &13.0 &13.2 &0.0 & & &
\\\hline
fci-max &17.3 &13.5 &13.7 &0.5 &0.0 & &
\\\hline
fci-k-mean &19.0 &15.2 &15.4 &2.0 &1.4 &0.0 &
\\\hline
fci-const-one &24.9 &20.9 &21.1 &7.0 &6.4 &4.9 &0.0
\\\hline
\end{tabular}
\end{latin}
\end{table}

\پاراگراف{مقایسه در سرعت و کیفیت یادگیری:} نتایج حاصل از اجرای الگوریتم‌ها در محیط صید و صیاد در شکل
\ref{fig:boltzmann/prey.pref.compare.png}
آمده است. همانطور که مشاهده می‌شود روش SEP دارای ٪۳ بهبود نسبت به IL می‌باشد ولی همانطور که مشاهده می‌کنیم روش پیشنهادی بهبود چشم‌گیری نسبت به روش SEP دارد و در بدترین حالت در صورت استفاده از تابع $\text{Mean}$ به عنوان مدل‌کننده‌ی تابع $g(\cdot)$ حدود ٪۱۷ نتایج بهبود می‌یابد و در صورتی‌که بخواهیم با استفاده از تابع $\text{Const-One}$ به صورت حریصانه عمل کنیم (یعنی در هنگام ترکیب دانش عامل‌ها، فقط دانش عاملی را درنظر بگیریم که با توجه به معیار خبرگی دارای بیشترین خبرگی می‌باشد) مطابق نتایج بدست آمده در محیط قبلی بهترین نتیجه‌ی ممکن یعنی حدود ٪۲۵ بهبود را بدست می‌آوریم؛ نتایج این قسمت را می‌توان در جدول
\ref{tab:prey_pref_compare}
خلاصه کرد.

\پاراگراف{مقایسه در سرعت اجرا:} در شکل
\ref{fig:boltzmann/prey.time.compare.png}
همانند شرایط طرح شده در محیط پلکان مارپیچ، سرعت اجرای الگوریتم‌ها آورده شده است. نتایج بدست آمده در محیط صید و صیاد همانند محیط پلکان مارپیچ نشان می‌دهد که روش پیشنهادی نسبت به روش SEP از سرعت اجرای بیشتری برخوردار است.

\fig[0.8]{boltzmann/prey.time.compare.png}{مقایسه در سرعت اجرای روش‌ها به ازای تعداد تلاش‌های متفاوت برحسب میلی‌ثانیه با تابع بولتزمن در محیط صید و صیاد}

\پاراگراف{مقایسه در میزان باروری:} همانطور که در شکل
\ref{fig:boltzmann/prey.qtable.max.compare.png}
مشاهده می‌کنیم روش معرفی شده در زمانی که به صورت تصادفی اقدام به انتخاب عمل می‌کند بیشتر از زمانی که IL و SEP با بصورت تصادفی اقدام به انتخاب عمل می‌کند جدول $Q$ را بارور می‌کند که از قدرت روش ارائه شده خبر می‌دهد. همچنین در مورد روش SEP می‌بینیم که در زمانی که بصورت تصادفی اقدام به عمل می‌کند باروری کمتری نسبت به روش پیشنهادی و IL دارد؛ یعنی میزان باروری روش SEP وابستگی زیادی به سیاست انتخاب عمل دارد و در صورت نداشتن سیاست انتخاب عمل خاصی بشدت عملکردش کاسته می‌شود ولی در روش پیشنهادی میزان این وابستگی از شدت کمتری برخوردار است که از دیگر امتیازات مثبت روش پیشنهادی می‌باشد -- همانند نتایج حاصله در محیط پلکان مارپیچ.

\fig[.8]{boltzmann/prey.qtable.max.compare.png}{نمودار باروری الگوریتم‌ها مختلف با تابع بولتزمن در محیط صید و صیاد}

\پاراگراف{مقایسه تاثیر تعداد عامل‌ها میزان کیفیت و سرعت یادگیری:}
همان‌طور که در شکل
\ref{fig:boltzmann/prey.multi-agent.pref.compare.png}
آمده است، روش SEP در زمانی ۲۰ عامل در حال یادگیری و اشتراک گذاری دانش‌های خود هستند نسبت به زمانی که فقط ۲ عامل در حال تعامل مشارکتی با محیط هستند فقط ٪۲ در خروجی الگوریتم تاثیر مثبت داشته است. این در حالی است که در همین شرایط میزان بهبود نتیجه‌ی روش پیشنهادی ٪۳۸ می‌باشد. که نشان می‌دهد روش SEP نسبت به افزایش تعداد عامل‌ها رفتاری تقریبا خنثی از خود نشان می‌دهد درحالی که روش پیشنهادی در ازای افزایش تعداد عامل‌ها به دلیل اینکه دانش جمعی نیز افزایش می‌یابد کیفیت خروجی آن نیز بهتر می‌شود -- دلایل و شهود این مساله همانند شهود مطرح شده در محیط صید و صیاد می‌باشد.

\fig[.8]{boltzmann/prey.multi-agent.pref.compare.png}{مقایسه تاثیر تعداد عامل‌ها میزان کیفیت و سرعت یادگیری با تابع بولتزمن در محیط صید و صیاد}

\پاراگراف{نتیجه‌گیری:} نتیجه‌ای که از مقایسه‌ی روش پیشنهادی در هر چهار مقایسه‌ی بالا می‌توان گرفت این است که روش پیشنهادی بهبود چشم‌گیری به روش SEP در محیط صید و صیاد و سیاست انتخاب عمل بولتزمن داده است.