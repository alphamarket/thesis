\قسمت{تحلیل نتایج}
در این قسمت به بررسی و تحلیل نتایج عددی که در بخش‌های قبلی این فصل آورده شده است می‌پردازیم. در تمامی آزمایش‌های انجام شده همانطور که مشاهده می‌شود که روش پیشنهادی از هر لحاظ از روش SEP نتایج بهتری بدست آورده است لذا در این بخش به بررسی علت‌های این برتری می‌پردازیم.

\زیرقسمت{مقایسه‌ی روش SEP با روش پیشنهادی}
جواب این سوال که «چرا روش پیشنهادی نسبت به روش SEP با اختلاف چشم‌گیری، نتایج بهتری ارائه داده است؟» دلیل زیر می‌باشد:
\begin{enumerate}
\فقره \textbf{فقدان وجود پراش\زیرنویس{Variance} دانشی بین عامل‌ها:} برای اینکه ترکیب دانش عامل‌ها موثر واقع شود باید یک پراشی بین دانش عامل‌ها وجود داشته باشد (یعنی عامل‌ها با دانش‌های مختلف از محیط وجود داشته باشد)، اگر همه‌ی عامل‌ها یک دانش را داشته باشند (پراش دانشی کمتری داشته باشند) نباید انتظار داشت که ترکیب دانش عامل‌ها دانشی فراتر از آنچه که در حالت کلی جمع دارند، نتیجه دهد. لذا نمودار شکل \ref{fig:boltzmann/maze.multi-agent.pref.compare.png} این نتیجه را می‌دهد که روش میرزایی در بین عامل‌ها با تجربیات متفاوت دانش‌های متفاوتی ایجاد نمی‌کند!
\فقره \textbf{کیفیت معیارها:} معیار‌های معرفی شده توسط میرزایی از کیفیت کافی برخوردار نیستند که نهایتا در کیفیت نتایج روش ارائه شده توسط ایشان تاثیر می‌گذارند.
\end{enumerate}

\زیرقسمت{مقایسه‌ی تابع بولتزمن و $\varepsilon$-حریصانه}
همانطور که در آزمایش‌ها مشاهده کردیم تابع بولتزمن از هر لحاظ نسبت به تابع $\varepsilon$-حریصانه نتایج بهتری تولید می‌کند و شهودی که به نظر می‌رسد دلیل این مساله می‌باشد این است که تابع $\varepsilon$-حریصانه در $\varepsilon$٪ مواقع بصورت کاملا تصادفی عمل می‌کند. حال فرض کنید عامل بعد از طی چند دوره به دانش نسبتا خوب نسبت به محیط خود رسیده است، در این صورت در هر حالت بخوبی می‌داند که کدام عمل به صلاح‌تر است، در صورتی که از تابع بولتزمن جهت انتخاب عمل استفاده کند این تابع احتمال انتخاب عملی که در این حالت به‌صلاح است را بیشتر می‌کند و عملی که تاثیر مخربی بر دست‌یابی عامل به اهداف خود دارد را احتمال انتخاب کمتری تخصیص می‌دهد؛ به همین دلیل در هر حالت احتمال انتخاب عملی که بهینه‌ است بیشتر است و به مرور که عامل دانش خود را نسبت به محیط کامل‌تر می‌کند این احتمال بیشتر تقویت می‌شود. در حالی که تابع $\varepsilon$-حریصانه فارغ از میزان دانش عامل از محیط در هر حالت $\varepsilon$٪ احتمال دارد که کاملا تصادفی انتخاب عمل کند و در این انتخاب تصادفی محتمل است که بدترین عمل انتخاب شود و این احتمال‌ها در طور یادگیری ثابت است لذا ممکن است در یک قدمی رسیدن به هدف عامل به صورت تصادفی یک عملی را انتخاب که کند که منجر عدم دست‌یابی به هدف یا دورشدن از هدف شود، به همین دلیل تابع $\varepsilon$-حریصانه نسبت به تابع بولتزمن باعث می‌‌شود عامل دیرتر به هدف برسد که همین مساله در معیارهای سنجش از قبیل سرعت و کیفیت یادگیری، سرعت اجرا تاثیر منفی می‌گذارد.

\زیرقسمت{بررسی تاثیر تعداد نواحی در کیفیت و سرعت یادگیری در روش پیشنهادی}
دلیل این مساله که «با توجه به شکل‌های \ref{fig:maze_refsize_effect} و \ref{fig:prey_refsize_effect} تعداد نواحی معیار تعریف شده در تعریف \ref{experties_definition} در سرعت و کیفیت یادگیری در روش پیشنهادی تاثیرگذار نیست.» این است که با توجه به تعریف \ref{experties_definition} یک همبستگی\زیرنویس{Correlation} مثبتی میان میزان ارجاع در نواحی ریز و نواحی درشت وجود دارد، زیرا که هرچه میزان ارجاع به نواحی ریز زیاد باشد همان میزان ارجاع به نواحی درشت (که شامل آن نواحی ریز می‌باشند) نیز زیاد می‌شود و برعکس هرچه میزان ارجاع به نواحی درشت کمتر باشد میزان ارجاع به نواحی زیرمجموعه‌ی آن نواحی درشت نیز کمتر است. بنابرین با توجه نحوه‌ی تعریف معیار مورد استفاده در تعریف \ref{experties_definition} تعداد نواحی در کیفیت و سرعت یادگیری تاثیرگذار نمی‌باشد.