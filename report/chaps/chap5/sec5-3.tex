\قسمت{مقایسه‌ی روش پیشنهادی با روش کوتاه‌ترین مسیر تجربه شده}
در این قسمت به مقایسه‌ی روش پیشنهادی با روش «کوتاه‌ترین مسیر تجربه شده» که از بروزترین تکنیک ارائه شده در این شاخه از یادگیری مشارکتی می‌باشد می‌پردازیم\مرجع{mohammad2015speedup}. کلیه‌ی این آزمایش‌ها در دو محیط «پلکان مارپیچ» و «صید و صیاد» صورت گرفته است. نتیجه‌ی هر آزمایش حاصل میانگین ۲۰ اجرای مستقل تمامی الگوریتم‌ها می‌باشد. همچنین به غیر از مواردی که صراحتا قید شده است تعداد عامل‌ها ۳ عدد می‌باشد -- البته بدیهی است که یادگیری مستقل تک عامله(یا به اختصار IL\زیرنویس{\مق{Individual Learning}}) شامل این قاعده نمی‌باشد. کلیه‌ی پارامتر‌های مربوط قسمت یادگیری مستقل الگوریتم \ref{alg:proposed} اعمال شده در آزمایشات این فصل منطبق بر پارامترهای تعریف شده در\مرجع{mohammad2015speedup} می‌باشد که نتایج قایل قیاس باشند. در ضمن در این فصل اختصارهای جدول \ref{tab:abbreviation} را نیز داریم.

\begin{table}[t]
\centering
\caption{لیست اختصارهای استفاده شده در این فصل}\label{tab:abbreviation}
\begin{tabular}{r|r}
اختصار & معنی
\\\midrule
\lr{REFMAT} & روش پیشنهادی\\
\lr{IL} & یادگیری مستقل تک عامله\\
\lr{SEP} & روش کوتاه‌ترین مسیر تجربه شده\\
\midrule
\lr{fci-max} & الگوریتم \مق{Max} به عنوان مدل کننده‌ی تابع $g(\cdot)$\\
\lr{fci-mean} & الگوریتم \مق{Mean} به عنوان مدل کننده‌ی تابع $g(\cdot)$\\
\lr{fci-k-mean} & الگوریتم \مق{K-Mean} به عنوان مدل کننده‌ی تابع $g(\cdot)$\\
\lr{fci-const-one} & الگوریتم \مق{Const-One} به عنوان مدل کننده‌ی تابع $g(\cdot)$\\
\midrule
\lr{Rand-Walk} & جستجوی کاملا مکاشفانه محیط\\
\bottomrule
\end{tabular}
\end{table}

در این فصل در حالت کلی ما در دو بخش سیاست انتخاب عمل «بولتزمن» و «$\varepsilon-$حریصانه» (که از این به بعد به اختصار «تابع بولتزمن» و «تابع حریصانه» خطاب خواهیم کرد.) به مقایسه‌ی نتایج می‌پردازیم. طبق آنچه که در ادامه مشاهده خواهیم کرد چه در صورت استفاده از تابع بولتزمن و چه تایع حریصانه روش پیشنهادی چه در سرعت یادگیری و چه در کیفیت یادگیری بهتر از روش SEP می‌باشد.

\include{sec5-3-maze}
\include{sec5-3-prey}