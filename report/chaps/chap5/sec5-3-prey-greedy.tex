\زیرزیرقسمت{سیاست انتخاب عمل «$\varepsilon$-حریصانه»}
\پاراگراف{مقایسه در سرعت و کیفیت یادگیری:} نتایج حاصل از اجرای الگوریتم‌ها در محیط صید و صیاد در شکل
\ref{fig:greedy/prey.pref.compare.png}
آمده است. شرایط این آزمایش به مشابه شرایط آزمایش با تابع بولتزمن می‌باشد.

\fig[.8]{greedy/prey.pref.compare.png}{مقایسه در سرعت و کیفیت یادگیری با تابع حریصانه در محیط صید و صیاد}

\begin{table}[h!]
\centering
\caption{مقایسه در میزان درصد بهبود کیفیت یادگیری در محیط صید و صیاد با تابع حریصانه}\label{tab:prey_pref_compare_greedy}
\begin{latin}
\begin{tabular}{|*8{l|}}
\hline
\multicolumn{3}{|c|}{}& \multicolumn{5}{c|}{REFMAT}
\\\hline
& IL & SEP & wsum & fci-mean & fci-max & fci-k-mean & fci-const-one
\\\hline
IL &0.0 & & & & & &
\\\hline
SEP &-1.3 &0.0 & & & & &
\\\hline
wsum &16.7 &18.3 &0.0 & & & &
\\\hline
fci-mean &31.7 &33.4 &12.8 &0.0 & & &
\\\hline
fci-max &36.8 &38.6 &17.2 &3.9 &0.0 & &
\\\hline
fci-k-mean &39.6 &41.5 &19.6 &6.0 &2.1 &0.0 &
\\\hline
fci-const-one &53.5 &55.5 &31.5 &16.6 &12.2 &10.0 &0.0
\\\hline
\end{tabular}
\end{latin}
\end{table}

همانطور که مشاهده می‌شود روش SEP دارای ۱-٪ بهبود نسبت به IL می‌باشد در حالی که روش پشنهادی در زمانی که از انتگرال فازی استفاده می‌کند در بدترین حالت دارای ۱۷٪ بهبود و در بهترین حالات دارای ۵۳٪ بهبود می‌باشد که نسبت به روش SEP تقریبا ۱۹ الی ۵۵ برابر نتیجه را بهبود داده است. در صورتی که از میانگین وزنی بجای انتگرال فازی استفاده شود نتایج با اختلافی حدود ۱۷٪ \زیرخط{بهتر} از یادگیری IL بوده است که نشان ‌می‌دهد که استفاده از انتگرال فازی چقدر می‌تواند نسبت به روش‌های سنتی و معمولی چون میانگین وزنی موثر واقع شود. میانگین نتایج این قسمت را می‌توان در جدول
\ref{tab:prey_pref_compare_greedy}
خلاصه کرد.

\پاراگراف{مقایسه در پیچیدگی زمانی:} در شکل
\ref{fig:greedy/prey.time.compare.png}
نیز می‌بینیم که در محیط صید و صیاد نیز روش پیشنهادی دارای پیچیدگی زمانی کمتری نسبت به روش SEP می‌باشد که نشان از بهینه‌گی روش پیشنهادی نسبت به روش SEP می‌دهد.

\fig[0.8]{greedy/prey.time.compare.png}{مقایسه در پیچیدگی زمانی روش‌ها به ازای تعداد تلاش‌های متفاوت برحسب میلی‌ثانیه با تابع حریصانه در محیط صید و صیاد}

\پاراگراف{مقایسه در میزان باروری:}
در شکل
\ref{fig:greedy/prey.qtable.max.compare.png}
میزان باروری IL از کلیه‌ی روش‌ها بهتر بوده (با اندک اختلاف نسبت روش پیشنهادی) ولی همچنان باروری روش پیشنهادی از روش SEP بیشتر بوده است و همچون آزمایش مشابه با تابع بولتزمن در اینجا نیز نشان داده شده است که روش SEP کاملا وابسته است به این‌که در هنگام انتخاب عمل بر اساس دانش عامل عمل شود و اگر عامل بدون درنظر گرفتن دانش عامل حرکتی اتخاذ کند میزان باروری عامل بشدت تحت تاثیر قرار می‌گیرد در حالی که در روش پیشنهادی در شرایط یکسان از کلیه الگوریتم‌ها میزان باروری بیشتری دارد.

\fig[.8]{greedy/prey.qtable.max.compare.png}{نمودار باروری الگوریتم‌ها مختلف با تابع حریصانه در محیط صید و صیاد}

\پاراگراف{مقایسه تاثیر تعداد عامل‌ها میزان کیفیت و سرعت یادگیری:} همان‌طور که در شکل
\ref{fig:greedy/prey.multi-agent.pref.compare.png}
آمده است، روش پیشنهادی و روش SEP به ازای تعداد عامل‌های ۲، ۳، ۵، ۱۰ و ۲۰ عدد به تعداد ۲۰ بار اجرا درآمده و میانگین اجراها به نمودار کشیده شده است. همانطور که می‌بینیم روش SEP در زمانی ۲۰ عامل در حال یادگیری و اشتراک گذاری دانش‌های خود هستند نسبت به زمانی که فقط ۲ عامل در حال تعامل مشارکتی با محیط هستند 9-٪ در خروجی الگوریتم تاثیر منفی داشته است؛ بدین معنی که در زمانی که از تابع حریصانه استفاده شود روش SEP به افزایش تعداد عامل فقط منجر به بدتر شدن عملکرد عامل‌ها در یادگیری مشارکتی می‌شود. این در حالی است که در همین شرایط میزان بهبود نتیجه‌ی روش پیشنهادی ۵۵٪ می‌باشد. که نشان می‌دهد روش پیشنهادی در ازای افزایش تعداد عامل‌ها به دلیل اینکه دانش جمعی نیز افزایش می‌یابد کیفیت خروجی آن نیز بطور چشم‌گیری بهتر می‌شود. در حالی که در روش SEP اگر کار نتایج بدتر نشود بهتر نمی‌شود که از ضعف بزرگ روش SEP خبر می‌دهد.

\fig[.8]{greedy/prey.multi-agent.pref.compare.png}{مقایسه تاثیر تعداد عامل‌ها میزان کیفیت و سرعت یادگیری با تابع حریصانه در محیط صید و صیاد}

\پاراگراف{نتیجه‌گیری:} نتیجه‌ای که از مقایسه‌ی روش پیشنهادی در هر چهار مقایسه‌ی بالا می‌توان گرفت همچون نتیجه‌ای که از نتایج تابع بولتزمن، روش پیشنهادی بهبود چشم‌گیری به روش SEP در محیط صید و صیاد و سیاست انتخاب عمل حریصانه داده است.