\قسمت{الگوریتم مورد مقایسه با روش پیشنهادی}
در فصل دوم به تشریح روش یادگیری مشارکتی بر مبنای «کوتاه‌ترین فاصله تجربه‌شده» پرداخته شد اما از آنجایی که بررسی عملکرد روش پیشنهادی در این پژوهش با کار میرزایی\مرجع{mohammad2015speedup} انجام‌شده است که مدرن‌ترین روش ارائه‌ی شده در این زمینه می‌باشد، لذا لازم است شناخت بیشتری از معیارهای به‌کاررفته در این کار صورت گیرد.

\زیرقسمت{معیار کوتاه‌ترین فاصله تجربه‌شده}
میرزایی معیاری با عنوان «کوتاه‌ترین فاصله تجربه‌شده» تعریف کرد\مرجع{mohammad2015speedup}، اما بهتر بود «کوتاه‌ترین فاصله استدلال شده» نامیده شود چراکه در روش محاسبه ارائه توسط ایشان کوتاه‌ترین مسیرهایی را که بتوان از مسیرهای تجربه‌شده استدلال کرد پیدا می‌نماید.

این معیار برای هر عمل از هر حالت مقداری در نظر می‌گیرد که در پایان هر چرخه یادگیری بروز رسانی می‌شود. جهت به‌روزرسانی این جدول یک ماتریس با نام $CP$\زیرنویس{\مق{Current Path}} در نظر گرفته‌ شده است که وظیفه نگهداری مسیر طی شده در هر چرخه را بر عهده دارد. این ماتریس به تعداد حالت‌های محیط ستون دارد و سه سطر دارد. مطابق با جدول \ref{tab:cp} در سلول $(1,i)$ آخرین عمل انجام‌شده در حالت $i$ انجام می‌شود، در سلول $(2,i)$ حالت مقصدی که عامل بعدازاین حالت مشاهده کرده و در سلول $(3,i)$ شماره آخرین گام حرکت در چرخه یادگیری فعلی که عامل در حالت $i$ بوده نگه‌داری می‌شود.

\begin{table}
\centering
\caption{ساختار جدول $CP$\مرجع{mohammad2015speedup}}\label{tab:cp}
\begin{tabular}{|c|c|c|}
\hline
$\cdots$ & آخرین عمل انجام شده در حالت $i$ & $\cdots$
\\\hline
$\cdots$ & حالت بعدی که مشاهده شده & $\cdots$
\\\hline
$\cdots$ & شماره آخرین گام حرکت مشاهده حالت $i$ & $\cdots$
\\\hline
\end{tabular}
\end{table}

بعد از اتمام هر چرخه یادگیری زمان بروز رسانی جدول $SEP$ با بهره‌گیری از جدول $CP$ است. در الگوریتم ارائه شده توسط میرزایی\مرجع{mohammad2015speedup} ابتدای سلول مربوط به عملی که در آخرین چرخه یادگیری انجام‌شده مقدار 1 می‌گیرد چراکه انجام این حرکت باعث رسیدن به نقطه هدف شده است پس فاصله این حرکت تا مقصد برابر با یک خواهد بود.بعد از آن به ترتیب معکوس گام‌های یادگیری سلول مربوط به اعمال انجام‌شده بروزرسانی میشود.جهت بروزرسانی مقدار یک خانه برابر حداقل مقدار مربوط به اعمال مقصد در همین جدول $SEP$ به‌علاوه 1 خواهد بود. چرا که فاصله حالت جاری تا حالت بعدی 1 بوده و جمع این فاصله با کوتاه‌ترین فاصله در حالت مجاور کوتاه‌ترین فاصله حالت جاری را خواهد ساخت.

\زیرقسمت{شوک}
بزرگ‌ترین دلیل رسیدن به یادگیری در یادگیری تقویتی پاداش‌های دریافتی برای انجام اعمال از محیط است. اما هرچه این اعمال به حالت پایانی نزدیک‌تر باشند باارزش‌تر هستند. میرزایی در\مرجع{mohammad2015speedup} معتقد است که پاداش دریافتی برای رسیدن به حالت‌های نهایی دارای ارزش بالاتری است و عامل حالتی که اثر بیشتری از این پاداش گرفته باشد بیشتر می‌شناسد. بر همین اساس در پارامتر شوک تعداد دفعاتی که اثر پاداش دریافتی از حالت‌های نهایی به هر خانه از جدول $Q$ رسیده است شمارش میشود. برای شمارش این کار کافی است در شروع یادگیری یک ماتریس در ابعاد ماتریس $Q$ با مقادیر اولیه 0 تولید کرده و پس از انجام هر عمل در صورتی که حالت بعدی حالت پایانی باشد یا حالتی باشد که قبلاً از پاداش حالت پایانی اثر گرفته باشد مقدار مربوط به آن عمل در جدول شوک یک واحد افزایش می‌یابد.